{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takes all current CDC probes and maps them against most recent sequences as they appear\n",
    "\n",
    "This is a work in progress, the scripts here yrack the RT-PCR assays currently being developed around the world and can be used to determine if they all work for all the circulating strains, given by GISAID.\n",
    "\n",
    "\n",
    "1. Collect Most recent CoronaVirus sequences and primers:\n",
    "\n",
    "I posted this here: https://www.dropbox.com/sh/h7m6c6adrea1jxz/AACDd1WYE0gy2jN5xWk_wfq7a?dl=0\n",
    "  \n",
    "  It has all the rt-PCR primers I've gotten so far as well as the latest GIAID equences.  \n",
    "  I'll keep this updated.\n",
    "\n",
    "2. Map Seqs to Genome\n",
    "\n",
    "3. Generate Labeled Databse: corona_<timestamp>_DB\n",
    "\n",
    "4. Runs primers against corona_<timestamp>_DB using simple BLAST.\n",
    "    \n",
    "Eventually, I will also computes Thermo WillItHyb willItPCR  for partial matches.\n",
    "    Like this study: https://graphgenomics.com/2020/02/20/pcr-predict-a-study-that-applies-machine-learning-techniques-to-the-real-worl/\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IO.py\n"
     ]
    }
   ],
   "source": [
    "#!pip install biopython\n",
    "import sys, os, copy, pprint, glob\n",
    "import datetime, json\n",
    "#import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from importlib import reload\n",
    "import pathlib, importlib\n",
    "import csv, fnmatch, random\n",
    "import Bio.Entrez #used by accessions_to_gb\n",
    "from ftplib import FTP\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('src/')\n",
    "import BLAST.BlastRun as BlastRun\n",
    "import utils.IO as IO\n",
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set a directory for work add sequences there:\n",
    "ud=\"/tdata1/betacoronavirus/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IO.py\n",
      "20200402T0853\n"
     ]
    }
   ],
   "source": [
    "reload(IO)\n",
    "tc=IO.TimeCode()\n",
    "print(tc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Latest Corona Seqs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### World Primer Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thi sis generated using the spreadsheet: Corona_RT-PCRprimers.xlsx\n",
    "\n",
    "primerLst=[\n",
    "       ['G1|F|CDC|2019-nCoV_N1-F', 'GACCCCAAAATCAGCGAAAT'],\n",
    "['G1|R|CDC|2019-nCoV_N1-R', 'TCTGGTTACTGCCAGTTGAATCTG'],\n",
    "['G1|P|CDC|2019-nCoV_N1-P', 'ACCCCGCATTACGTTTGGTGGACC'],\n",
    "['G2|F|CDC|2019-nCoV_N2-F', 'TTACAAACATTGGCCGCAAA'],\n",
    "['G2|R|CDC|2019-nCoV_N2-R', 'GCGCGACATTCCGAAGAA'],\n",
    "['G2|P|CDC|2019-nCoV_N2-P', 'ACAATTTGCCCCCAGCGCTTCAG'],\n",
    "['G3|F|CDC|2019-nCoV_N3-F', 'GGGAGCCTTGAATACACCAAAA'],\n",
    "['G3|R|CDC|2019-nCoV_N3-R', 'TGTAGCACGATTGCAGCATTG'],\n",
    "['G3|P|CDC|2019-nCoV_N3-P', 'AYCACATTGGCACCCGCAATCCTG'],\n",
    "['G4|F|CDC|RP-F', 'AGATTTGGACCTGCGAGCG'],\n",
    "['G4|R|CDC|RP-R', 'GAGCGGCTGTCTCCACAAGT'],\n",
    "['G4|P|CDC|RP-P', 'TTCTGACCTGAAGGCTCTGCGCG'],\n",
    "\n",
    "\n",
    "\n",
    "['G5|P|CDC-2|IN-2', 'GGGTTGGGACTATCCTAAGTGTGA'],\n",
    "['G6|P|CDC-2|IN-4', 'TAACACACAACICCATCATCA'],\n",
    "['G5|F|CDC-2|Cor-p-F2', 'CTAACATGCTTAGGATAATGG'],\n",
    "['G6|F|CDC-2|Cor-p-F3', 'GCCTCTCTTGTTCTTGCTCGC'],\n",
    "['G5|R|CDC-2|Cor-p-R1', 'CAGGTAAGCGTAAAACTCATC'],\n",
    "['G6|R|CDC-3|Cor-p-R2', 'CAGGTAAGCGTAAAACTCATC'],\n",
    "\n",
    "['G7|F|China|ORF1ab_F', 'CCCTGTGGGTTTTACACTTAA '],\n",
    "['G7|R|China|ORF1ab_R', 'ACGATTGTGCATCAGCTGA '],\n",
    "['G7|P|China|ORF1ab_P', 'CCGTCTGCGGTATGTGGAAAGGTTATGG'],\n",
    "['G8|F|China|N_F', 'GGGGAACTTCTCCTGCTAGAAT '],\n",
    "['G8|R|China|N_R', 'CAGACATTTTGCTCTCAAGCTG '],\n",
    "['G8|P|China|N_P', 'TTGCTGCTGCTTGACAGATT'],\n",
    "\n",
    "['G10|F|Germany|RdRP_SARSr-F2', 'GTGARATGGTCATGTGTGGCGG'],\n",
    "['G9|R|Germany|RdRP_SARSr-R1', 'CARATGTTAAASACACTATTAGCATA'],\n",
    "['G10|P|Germany|RdRP_SARSr-P2', 'CAGGTGGAACCTCATCAGGAGATGC'],\n",
    "['G9|P|Germany|RdRP_SARSr-P1', 'CCAGGTGGWACRTCATCMGGTGATGC'],\n",
    "['G9|F|Germany|E_Sarbeco_F1', 'ACAGGTACGTTAATAGTTAATAGCGT'],\n",
    "['G10|R|Germany|E_Sarbeco_R2', 'ATATTGCAGCAGTACGCACACA'],\n",
    "['G9|P|Germany|E_Sarbeco_P1', 'ACACTAGCCATCCTTACTGCGCTTCG'],\n",
    "\n",
    "['G11|F|HongKong|HKU-ORF1b-nsp14F', 'TGGGGYTTTACRGGTAACCT'],\n",
    "['G11|R|HongKong|HKU-ORF1b-nsp14R', 'AACRCGCTTAACAAAGCACTC'],\n",
    "['G11|P|HongKong|HKU-ORF1b-nsp141P', 'TAGTTGTGATGCWATCATGACTAG'],\n",
    "['G12|F|HongKong|HKU-NF', 'TAATCAGACAAGGAACTGATTA'],\n",
    "['G12|R|HongKong|HKU-NR', 'CGAAGGTGTGACTTCCATG'],\n",
    "['G12|P|HongKong|HKU-NP', 'GCAAATTGTGCAATTTGCGG'],\n",
    "\n",
    "['G13|F|Thailand|WH-NIC_N-F', 'CGTTTGGTGGACCCTCAGAT'],\n",
    "['G13|R|Thailand|WH-NIC_N-R', 'CCCCACTGCGTTCTCCATT'],\n",
    "['G13|P|Thailand|WH-NIC_N-P', 'CAACTGGCAGTAACCA'],\n",
    "\n",
    "['G14|F|Japan|NIID_WH-1_F501_F', 'TTCGGATGCTCGAACTGCACC'],\n",
    "['G14|R|Japan|NIID_WH-1_R913_R', 'CTTTACCAGCACGTGCTAGAAGG'],\n",
    "['G14|F|Japan|NIID_WH-1_F509_F', 'CTCGAACTGCACCTCATGG'],\n",
    "['G15|R|Japan|NIID_WH-1_R854_R', 'CAGAAGTTGTTATCGACATAGC'],\n",
    "['G15|F|Japan|NIID_WH-1_Seq_F519_F', 'ACCTCATGGTCATGTTATGG'],\n",
    "['G15|R|Japan|NIID_WH-1_Seq_R840_R', 'GACATAGCGAGTGTATGCC'],\n",
    "['G16|F|Japan|WuhanCoV-spk1-f_F', 'TTGGCAAAATTCAAGACTCACTTT'],\n",
    "['G16|R|Japan|WuhanCoV-spk2-r_R', 'TGTGGTTCATAAAAATTCCTTTGTG'],\n",
    "['G17|F|Japan|NIID_WH-1_F24381_F', 'TCAAGACTCACTTTCTTCCAC'],\n",
    "['G17|R|Japan|NIID_WH-1_R24873_R', 'ATTTGAAACAAAGACACCTTCAC'],\n",
    "['G18|F|Japan|NIID_WH-1_Seq_F24383_F', 'AAGACTCACTTTCTTCCACAG'],\n",
    "['G18|R|Japan|NIID_WH-1_Seq_R24865_R', 'CAAAGACACCTTCACGAGG'],\n",
    "['G19|F|Japan|NIID_2019-nCOV_N_F2_F', 'AAATTTTGGGGACCAGGAAC'],\n",
    "['G19|R|Japan|NIID_2019-nCOV_N_R2_R', 'TGGCAGCTGTGTAGGTCAAC'],\n",
    "['G19|P|Japan|NIID_2019-nCOV_N_P2_P', 'ATGTCGCGCATTGGCATGGA'],\n",
    "\n",
    "['G20|F|France|nCoV_IP2-12669Fw_F', 'ATGAGCTTAGTCCTGTTG'],\n",
    "['G20|R|France|nCoV_IP2-12759Rv_R', 'CTCCCTTTGTTGTGTTGT'],\n",
    "['G20|P|France|nCoV_IP2-12696bProbe(+)', 'AGATGTCTTGTGCTGCCGGTA'],\n",
    "['G21|F|France|nCoV_IP4-14059Fw', 'GGTAACTGGTATGATTTCG'],\n",
    "['G21|R|France|nCoV_IP4-14146Rv', 'CTGGTCAAGGTTAATATAGG'],\n",
    "['G21|P|France|nCoV_IP4-14084Probe(+)', 'TCATACAAACCACGCCAGG'],\n",
    "['G22|F|France|E_Sarbeco_F1', 'ACAGGTACGTTAATAGTTAATAGCGT'],\n",
    "['G22|R|France|E_Sarbeco_R2', 'ATATTGCAGCAGTACGCACACA'],\n",
    "['G22|P|France|E_Sarbeco_P1', 'ACACTAGCCATCCTTACTGCGCTTCG'],\n",
    "\n",
    "['G25|F|eurosurveillance|RdRp_SARSr-F', 'GTGARATGGTCATGTGTGGCGG'],\n",
    "['G25|P1|eurosurveillance|RdRp_SARSr-P2', 'CAGGTGGAACCTCATCAGGAGATGC'],\n",
    "['G25|P|eurosurveillance|RdRP_SARSr-P1', 'CCAGGTGGWACRTCATCMGGTGATGC'],\n",
    "['G25|R|eurosurveillance|RdRp_SARSr-R', 'CARATGTTAAASACACTATTAGCATA'],\n",
    "['G26|F|eurosurveillance|E_Sarbeco_F', 'ACAGGTACGTTAATAGTTAATAGCGT'],\n",
    "['G26|P|eurosurveillance|E_Sarbeco_P1', 'ACACTAGCCATCCTTACTGCGCTTCG'],\n",
    "['G26|R|eurosurveillance|E_Sarbeco_R', 'ATATTGCAGCAGTACGCACACA'],\n",
    "['G27|F|eurosurveillance|N_Sarbeco_F', 'CACATTGGCACCCGCAATC'],\n",
    "['G27|P|eurosurveillance|N_Sarbeco_P', 'ACTTCCTCAAGGAACAACATTGCCA'],\n",
    "['G27|R|eurosurveillance|N_Sarbeco_R', 'GAGGAACGAGAAGAGGCTTG'],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collate Sequences/FDB/RunBlast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inFASTA_yield(/tdata1/betacoronavirus/gisaid_cov2020_sequences.fasta)  num_seqs: 3228\n",
      "cmdstr: cd /tdata1/betacoronavirus;makeblastdb  -in /tdata1/betacoronavirus/gisaid_cov2020.fa -out /tdata1/betacoronavirus/corona_bg -input_type fasta -dbtype nucl -parse_seqids;\n",
      "cmdstr: blastdbcmd -db /tdata1/betacoronavirus/corona_bg -entry all -outfmt \"%t %l\"|tee /tdata1/betacoronavirus/SLST.TXT\n",
      "ListBlastDB: returning 3228 recs\n",
      "cmdstr: blastdbcmd -db /tdata1/betacoronavirus/corona_bg -entry all -outfmt \"%t %l\"|tee /tdata1/betacoronavirus/SLST.TXT\n",
      "ListBlastDB: returning 3228 recs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tdata1/betacoronavirus/corona_bg'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(BlastRun)\n",
    "bg_fileLst=[\n",
    "                'gisaid_cov2020_sequences.fasta',\n",
    "    \n",
    "    #uncommenting these lines does run against all coronviruses\n",
    "#             'alphacorona_sequence_genomes.fasta', \n",
    "#             'deltacorona_sequence_genomes.fasta', \n",
    "#             'gammacorona_sequence_genomes.fasta', \n",
    "#             'betacorona_sequence_genomes.txt',\n",
    "           ]\n",
    "query_path='corona_PCRPrimers.fa'\n",
    "bg_pth=ud+'gisaid_cov2020.fa'\n",
    "\n",
    "fastaLst=[];subj_seq_dict={}\n",
    "fp=open(bg_pth, 'w')\n",
    "for bg_fn in bg_fileLst:\n",
    "    group_name=bg_fn.split('_')[0]\n",
    "    if group_name=='gisaid':\n",
    "        group_name='covid19'\n",
    "    c_type=bg_fn.split('_')[0]\n",
    "    for faObj in IO.inFASTA_yield(ud+bg_fn):\n",
    "        fastaLst.append([c_type, faObj[0]])\n",
    "        label, seq=faObj[:2]\n",
    "        if '[' in label:\n",
    "            label=label.replace('[', '').replace(']', '')\n",
    "            lablst=label.split(' ')\n",
    "            label='|'.join(lablst)\n",
    "            \n",
    "        label=label.split(' ')[0]#Blast cuts your label off after the first space\n",
    "        label=\"%s|%s|%i\"%(group_name, label, len(seq))\n",
    "        fp.write(\">%s\\n%s\\n\"%(label, seq))\n",
    "        subj_seq_dict[label]=seq\n",
    "fp.close()\n",
    "\n",
    "df=pd.DataFrame(fastaLst, columns=['c_type', 'fa_label'])\n",
    "#df.to_csv(ud+'fasta_labels.csv')\n",
    "\n",
    "fdb_path=ud+'corona_bg'\n",
    "subj_FDB = BlastRun.FormatDB(bg_pth, fdb_path, input_type='fasta', dbtype = 'nucl', title = \"\")\n",
    "subj_FDB.RunFromFDB(parse_seqids=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Map Seqs to Genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(BlastRun)\n",
    "import json\n",
    "\n",
    "class primer_hit:\n",
    "    def __init__(self, hit, query_fa):\n",
    "        self.query_name, self.query_seq = query_fa[:2]\n",
    "        self.query_len=len(self.query_seq)\n",
    "        self.subj_label=hit['description'][0]['title']\n",
    "        self.subj_acc=hit['description'][0]['accession']\n",
    "        self.num_hsp=len(hit['hsps'])\n",
    "        self.hit_id=hit['num']\n",
    "        hsp=hit['hsps'][0]\n",
    "        self.score=hsp['score']\n",
    "        self.identity=hsp['identity']\n",
    "        self.similarity_score=self.identity/float(self.query_len)\n",
    "        \n",
    "        self.query_start=int(hsp['query_from'])\n",
    "        self.query_to=int(hsp['query_to'])\n",
    "        self.query_strand=hsp['query_strand']\n",
    "        \n",
    "        self.subj_start=int(hsp['hit_from'])\n",
    "        self.subj_to=int(hsp['hit_to'])\n",
    "        self.subj_strand=hsp['hit_strand']\n",
    "        self.same_strand=self.query_strand==self.subj_strand\n",
    "        self.subj_seq=''\n",
    "    def set_subj_seq(self, subj_dict, seq_buffer=20):\n",
    "        s=min(0, min(self.subj_start, self.subj_to)-seq_buffer)\n",
    "        e=max(self.subj_start, self.subj_to)+seq_buffer\n",
    "        self.subj_seq=subj_dict[self.subj_label][s:e]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class PCRRunner:\n",
    "    def __init__(self, ud, primerLst, blast_fdb, subj_seq_dict, group='test'):\n",
    "        self.ud=ud\n",
    "        self.group=group\n",
    "        self.primer_dict=dict([label,seq] for label,seq in primerLst)\n",
    "        self.bi_path=self.ud+'corona_PCRPrimers_%s.fa'%self.group\n",
    "        self.make_primer_BI()\n",
    "        self.blast_fdb=blast_fdb\n",
    "        self.subj_seq_dict=subj_seq_dict\n",
    "        self.subj_template_dict={}\n",
    "        self.blast_params={\n",
    "                  'dust':\"no\",\n",
    "                  'outfmt':15,\n",
    "                  'num_threads':15,\n",
    "                  'word_size':7,\n",
    "                  'max_target_seqs': 100000\n",
    "                  }\n",
    "        \n",
    "        self.rec=dict((k.split('|')[1],k) for k in self.primer_dict.keys())\n",
    "        self.run_blast()\n",
    "    def make_primer_BI(self):\n",
    "        ud=\"/tdata1/betacoronavirus/\"\n",
    "        fp=open(self.bi_path, 'w')\n",
    "        fp.write('\\n'.join(['>%s\\n%s'%(label, seq) for label, seq in self.primer_dict.items()]))\n",
    "        fp.close()\n",
    "    def run_blast(self):\n",
    "        print(\"run_blast\")\n",
    "        self.bo_path=ud+'bo_primer_corona.txt'\n",
    "        BR=BlastRun.BlastRunObj(self.bi_path, self.bo_path, self.blast_fdb, blast_params=self.blast_params)\n",
    "        print(BR.cmd)\n",
    "        self.bo_path=BR.RunBlast()\n",
    "    def parse_blast(self, seq_buffer=10):\n",
    "        bo_json=json.loads(open(self.bo_path).read())\n",
    "        self.primer_hit_dict={}\n",
    "        for bb in bo_json[\"BlastOutput2\"]:\n",
    "            report=bb[\"report\"]\n",
    "            query_label=report['results'][\"search\"][\"query_title\"]\n",
    "            query_seq=self.primer_dict[query_label]\n",
    "            query_fa=[query_label, query_seq]\n",
    "            if not query_label in self.primer_hit_dict:\n",
    "                self.primer_hit_dict[query_label]={}\n",
    "            for hit in report['results'][\"search\"][\"hits\"]:\n",
    "                ph=primer_hit(hit, query_fa)\n",
    "                if not(ph.subj_label in self.primer_hit_dict[query_label]):\n",
    "                    self.primer_hit_dict[query_label][ph.subj_label]=[]\n",
    "                self.primer_hit_dict[query_label][ph.subj_label].append(ph)\n",
    "        #set subj_seq\n",
    "        oLst=[]\n",
    "        for query_label in self.primer_hit_dict.keys():\n",
    "            for subj_label in self.primer_hit_dict[query_label].keys():\n",
    "                phLst=self.primer_hit_dict[query_label][subj_label]\n",
    "                subj_se=[]\n",
    "                for ph in phLst:\n",
    "                    subj_se.append(ph.subj_start)\n",
    "                    subj_se.append(ph.subj_to)\n",
    "                s_start=min(subj_se)\n",
    "                s_end=max(subj_se)\n",
    "                s=max(0, s_start-seq_buffer)\n",
    "                e=s_end+seq_buffer\n",
    "                subj_seq=self.subj_seq_dict[subj_label][s:e]\n",
    "                rec=[subj_label, s_start, s_end, subj_seq]\n",
    "                if not(subj_label in self.rec):self.rec[subj_label]=0\n",
    "                for ph in phLst:\n",
    "                    ph.subj_seq=subj_seq\n",
    "                    self.rec[subj_label]+=ph.similarity_score\n",
    "    def compute_pcr_wip(self):\n",
    "        if self.same_strand:\n",
    "            pcr_wip=SWT.TM.WillItPCR(self.subj_seq, f_primer, r_primer)\n",
    "        else:\n",
    "            s=amplicon_hit.send-buffer\n",
    "            e=amplicon_hit.sstart+buffer\n",
    "            hit_seq=seq_pos_dict[amplicon_hit.subject].getSeq()[s:e]\n",
    "            as_hit_seq=MolBio.Antisense(hit_seq)\n",
    "            sas='anti'\n",
    "            pcr_wip=SWT.TM.WillItPCR(as_hit_seq, MolBio.Antisense(r_primer), MolBio.Antisense(f_primer))\n",
    "        pcr_wip['amplicon_name']=q_label\n",
    "        pcr_wip['amplicon']=amplicon\n",
    "        pcr_wip['amplicon_region']=hit_seq\n",
    "        pcr_wip['amplicon_region_len']=len(hit_seq)\n",
    "        pcr_wip['amplicon_pos']=\"subj:%s|%i:%i|len:%i\"%(amplicon_hit.subject, s,e,len(hit_seq))\n",
    "        pcr_wip['f_primer']=f_primer\n",
    "        pcr_wip['r_primer']=r_primer\n",
    "        pcr_wip['sas']=sas\n",
    "        pcr_wip['amplicon_hit']='|'.join(amplicon_hit.hitLst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n",
      "run_blast\n",
      "blastn  -query /tdata1/betacoronavirus/corona_PCRPrimers_test.fa -out /tdata1/betacoronavirus/bo_primer_corona.txt -db /tdata1/betacoronavirus/corona_bg -dust no -outfmt 15 -num_threads 15 -word_size 7 -max_target_seqs 100000;\n"
     ]
    }
   ],
   "source": [
    "oLst=[]\n",
    "for plst in IO.groupby(primerLst, key=lambda x:x[0].split('|')[0]):\n",
    "    P=PCRRunner(ud, plst, fdb_path, subj_seq_dict, group='test')\n",
    "    P.parse_blast(seq_buffer=10)\n",
    "    oLst.append(P)\n",
    "    \n",
    "    \n",
    "df=pd.DataFrame([P.rec for P in oLst])\n",
    "df.to_csv(ud+'test_pcr_%s.csv'%tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(ud+'test_pcr_%s.csv'%tc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOT Implemented Yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Runs primers against corona_timestamp_DB and computes Thermo WillItHyb willItPCR \n",
    "\n",
    "For imperfect primers: compute willItHyb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'MolBio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-6f69e4669e2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mThermo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMolBio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mMolBio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mThermo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSWThermo\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mSWT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSWT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/covid19/src/Thermo/SWThermo.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#from string import maketrans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTwodArray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mTD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mMolBio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mMB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mVerbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'MolBio'"
     ]
    }
   ],
   "source": [
    "import Thermo.MolBio as MolBio\n",
    "import Thermo.SWThermo as SWT\n",
    "reload(GT)\n",
    "reload(SWT)\n",
    "\n",
    "def AlignHit(h, seq_pos_dict, aquery_dict, buffer=10):\n",
    "    \"\"\"\n",
    "    This builds a pretty alignment\n",
    "    \"\"\"\n",
    "    #print('aquery_dict[h.query]', aquery_dict[h.query])\n",
    "    q_label, amplicon, f_primer, r_primer = aquery_dict[h.query]\n",
    "    sas=''\n",
    "    if h.sense:\n",
    "        hit_seq=seq_pos_dict[h.subject].getSeq()[max(0,(h.sstart-buffer)):(h.send+buffer)]\n",
    "    else:\n",
    "        hit_seq=MolBio.Antisense(seq_pos_dict[h.subject].getSeq()[max(0,(h.send-buffer)):(h.sstart+buffer)])\n",
    "        sas='anti'\n",
    "    return '\\\"%s\\\"'%('\\r'.join([\"%s_%s-sense\"%(q_label, sas),hit_seq, f_primer, r_primer]))\n",
    "\n",
    "def ThermoPCRHit(amplicon_hit, seq_pos_dict, aquery_dict, buffer=10):\n",
    "    \"\"\"For amplicon_hit it retrieves sequence Plus buffer from subj DataBase Then it computes ThermoPCRHit\n",
    "        amplicon_hit: GT.hit\n",
    "        seq_pos_dict: from IO.SetUp_SequenceRetrievalSystem(glob_str, pool_sz=15)\n",
    "        aquery_dict: stores (q_label, amplicon, f_primer, r_primer, full_seq) by probe query name\n",
    "        buffer: how much extra sequence to retrieve from database\n",
    "        \"\"\"\n",
    "    q_label, amplicon, f_primer, r_primer = aquery_dict[amplicon_hit.query]\n",
    "    sas=''\n",
    "    if amplicon_hit.sense:\n",
    "        s=amplicon_hit.sstart-buffer\n",
    "        e=amplicon_hit.send+buffer\n",
    "        hit_seq=seq_pos_dict[amplicon_hit.subject].getSeq()[s:e]\n",
    "        pcr_wip=SWT.TM.WillItPCR(hit_seq, f_primer, r_primer)\n",
    "    else:\n",
    "        s=amplicon_hit.send-buffer\n",
    "        e=amplicon_hit.sstart+buffer\n",
    "        hit_seq=seq_pos_dict[amplicon_hit.subject].getSeq()[s:e]\n",
    "        as_hit_seq=MolBio.Antisense(hit_seq)\n",
    "        sas='anti'\n",
    "        pcr_wip=SWT.TM.WillItPCR(as_hit_seq, MolBio.Antisense(r_primer), MolBio.Antisense(f_primer))\n",
    "    pcr_wip['amplicon_name']=q_label\n",
    "    pcr_wip['amplicon']=amplicon\n",
    "    pcr_wip['amplicon_region']=hit_seq\n",
    "    pcr_wip['amplicon_region_len']=len(hit_seq)\n",
    "    pcr_wip['amplicon_pos']=\"subj:%s|%i:%i|len:%i\"%(amplicon_hit.subject, s,e,len(hit_seq))\n",
    "    pcr_wip['f_primer']=f_primer\n",
    "    pcr_wip['r_primer']=r_primer\n",
    "    pcr_wip['sas']=sas\n",
    "    pcr_wip['amplicon_hit']='|'.join(amplicon_hit.hitLst)\n",
    "    return pcr_wip\n",
    "\n",
    "\n",
    "def Run_ThermoPCRHit(query_faLst, subj_Lst, seq_pos_dict, bo_path, out_path, pcr_predict_model=None, SIM_SIM_LIMIT=None):\n",
    "    \"\"\"\n",
    "    Takes PCR reactions and predicts hits to databases of genomes\n",
    "    query_faLst:     'label', 'amplicon', 'pcr_for', 'pcr_rev'\n",
    "    subj_Lst:         List of subj genomes from [x[0] for x in list(subj_FDB.ListBlastDB())]\n",
    "    seq_pos_dict:     from IO.SetUp_SequenceRetrievalSystem(glob_str, pool_sz=15)\n",
    "    bo_path:          Blast_output path\n",
    "    out_path:         out_path\n",
    "    SIM_SIM_LIMIT:    aux similarity threshold\n",
    "    \"\"\"\n",
    "    _query_dict={}\n",
    "    for p in query_faLst:\n",
    "        _query_dict[p[0]]=p\n",
    "    fasta_sz_dict={}\n",
    "    for fa in query_faLst:\n",
    "        fasta_sz_dict[fa[0]] = len(fa[1])\n",
    "    ll = ['label']\n",
    "    sll = ['align_label']\n",
    "    oLst = [[subj_label] for subj_label in subj_Lst]\n",
    "    sLst = [['align_%s'%subj_label] for subj_label in subj_Lst]\n",
    "    thermoLst=[]\n",
    "    N=0\n",
    "    for hitLst in GT.StreamParseBlastQueryGroupBy(bo_path, hit_similarity_lambda = lambda x:x.percid>50.0, Verbosity=0.0):\n",
    "        if not(hitLst):continue\n",
    "        query = hitLst[0].query\n",
    "        map_gene=query#.split('|')[0]\n",
    "        print('query', query, 'num_hits: %i'%len(hitLst))\n",
    "        q_len = fasta_sz_dict[query]\n",
    "        ll.append(\"%s [len=%i]\"%(query, q_len))\n",
    "        sll.append(\"%s align\"%(query))\n",
    "        d={}\n",
    "        for hit in hitLst:\n",
    "            seq_sim = hit.SeqSimilarity(q_len)\n",
    "            if SIM_SIM_LIMIT:\n",
    "                if seq_sim<SIM_SIM_LIMIT:\n",
    "                    print('SIM_SIM_LIMIT: skipping', hit.query, hit.subject, seq_sim)\n",
    "                    continue\n",
    "            hit.seq_sim = seq_sim\n",
    "            esc = hit.subject\n",
    "            if not(esc in d):\n",
    "                d[esc]=hit\n",
    "            if hit.seq_sim>d[esc].seq_sim:\n",
    "                d[esc]=hit\n",
    "        for i in range(len(oLst)):\n",
    "            esc=oLst[i][0]\n",
    "            if esc in d:\n",
    "                oLst[i].append(d[esc].seq_sim)\n",
    "            else:\n",
    "                oLst[i].append(0)\n",
    "        for i in range(len(sLst)):\n",
    "            esc=oLst[i][0]\n",
    "            if esc in d:\n",
    "                #sLst[i].append(AlignHit(d[esc], seq_pos_dict, _query_dict))\n",
    "                swip = ThermoPCRHit(d[esc], seq_pos_dict, _query_dict, buffer=60)\n",
    "                swip['query_primerset']=query\n",
    "                swip['subj_genome']=esc\n",
    "                swip['blast_sim']=d[esc].seq_sim#BLAST Similarity\n",
    "                thermoLst.append(swip)\n",
    "                if pcr_predict_model:\n",
    "                    sLst[i].append(PCR_model_Predict(swip, pcr_predict_model))\n",
    "                else:\n",
    "                    try:\n",
    "                        sLst[i].append(min(swip['for_align_score'], swip['rev_align_score']))\n",
    "                    except:\n",
    "                        sLst[i].append('')\n",
    "            else:\n",
    "                sLst[i].append('n/a')\n",
    "        N+=1\n",
    "        #if N>0:break\n",
    "    for i in range(len(oLst)):\n",
    "        oLst[i].extend(sLst[i])\n",
    "        oLst[i].append('_')\n",
    "    LL=ll+sll+['sep']\n",
    "    thermoLst_df=pd.DataFrame(thermoLst)\n",
    "    thermoLst_df.to_csv(out_path+'_thermo.csv')\n",
    "    df = pd.DataFrame.from_records(oLst, columns=LL)\n",
    "    df.to_csv(out_path)\n",
    "    return df, thermoLst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  joblib\n",
    "import Probe.MolBio as MB\n",
    "reload(MB)\n",
    "reload(SWT)\n",
    "\n",
    "pcr_predict_model=    joblib.load('/home/ubuntu/git/Genotyper/src/Probe/PCRPredictModel_depth6.joblib')\n",
    "alt_pcr_predict_model=joblib.load('/home/ubuntu/git/Genotyper/src/Probe/PCRPredictModel_deltaTm_depth6.joblib')\n",
    "def Compute_pcr_wip(amplicon, for_primer, rev_primer, align_sum_thresh=0.5):\n",
    "    #Tests to make sure your anti setting is correct\n",
    "    pcr_wip=SWT.TM.WillItPCR(amplicon, for_primer, rev_primer)\n",
    "    pcr_wip['flipped_align_delta']=''\n",
    "    align_sum=pcr_wip['for_align_score']+pcr_wip['rev_align_score']\n",
    "    if align_sum<align_sum_thresh:\n",
    "        pcr_wip=SWT.TM.WillItPCR(MB.Antisense(amplicon), for_primer, rev_primer)\n",
    "        flipped_align_sum=pcr_wip['for_align_score']+pcr_wip['rev_align_score']\n",
    "        pcr_wip['flipped_align_delta']=flipped_align_sum-align_sum\n",
    "    return pcr_wip\n",
    "\n",
    "def PCR_model_Predict(pcr_wip, pcr_predict_model):\n",
    "    if not('for_Tm' in pcr_wip) or not('rev_Tm' in pcr_wip):\n",
    "        return 0.0\n",
    "    for_rev_delta=pcr_wip['for_Tm']-pcr_wip['rev_Tm']\n",
    "    if for_rev_delta>0:\n",
    "        fr='rev'\n",
    "    else:\n",
    "        fr='for'\n",
    "    #attributes=['Tm', 'align_score', 'mis_matches', 'three_prime_mm', 'three_prime_overhang']\n",
    "    attributes=['deltaTm', 'align_score','mis_matches', 'three_prime_mm', 'three_prime_overhang']\n",
    "    d={}\n",
    "    for k in attributes:\n",
    "        d[k]=pcr_wip['%s_%s'%(fr, k)]\n",
    "    d['three_prime_overhang']= 0 if d['three_prime_overhang']<0 else d['three_prime_overhang']\n",
    "    d['three_prime_mm']= 0 if not(d['three_prime_mm']) else d['three_prime_mm']\n",
    "    X=np.array([d[k] for k in attributes]).reshape(1, -1)\n",
    "    d['predict']=pcr_predict_model.predict_proba(X)\n",
    "    return d['predict'][0][1]\n",
    "\n",
    "    \n",
    "    \n",
    "def PCRPredict(for_primer, rev_primer, amplicon, sas, \n",
    "               pcr_predict_model, \n",
    "               attributes=['align_score','mis_matches', 'three_prime_mm', 'three_prime_overhang'], \n",
    "               ReturnPassProb=True):\n",
    "    if sas=='anti':\n",
    "        amplicon=MB.Antisense(amplicon)\n",
    "    pcr_wip=Compute_pcr_wip(amplicon, for_primer, rev_primer, align_sum_thresh=0.5)\n",
    "    if not('for_Tm' in pcr_wip) or not('rev_Tm' in pcr_wip):\n",
    "        if ReturnPassProb:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return [0,0,0,0] + [0.0]\n",
    "    for_rev_delta=pcr_wip['for_Tm']-pcr_wip['rev_Tm']\n",
    "    if for_rev_delta>0:\n",
    "        fr='rev'\n",
    "    else:\n",
    "        fr='for'\n",
    "    d={}\n",
    "    for k in attributes:\n",
    "        d[k]=pcr_wip['%s_%s'%(fr, k)]\n",
    "    d['three_prime_overhang']= 0 if d['three_prime_overhang']<0 else d['three_prime_overhang']\n",
    "    d['three_prime_mm']= 0 if not(d['three_prime_mm']) else d['three_prime_mm']\n",
    "    X=np.array([d[k] for k in attributes]).reshape(1, -1)\n",
    "    d['predict']=pcr_predict_model.predict_proba(X)\n",
    "    #d['predict']=clf.predict_proba(X)\n",
    "    d['pass_prob']=d['predict'][0][1]\n",
    "    #print('X', X)#, d['predict'])\n",
    "    if ReturnPassProb:\n",
    "        return d['pass_prob']\n",
    "    if pcr_wip['flipped_align_delta']: print('flipped_align_delta', pcr_wip['flipped_align_delta'])\n",
    "    return [d[k] for k in attributes] + [d['pass_prob']]\n",
    "    \n",
    "\n",
    "\n",
    "p=PCRPredict(for_primer, rev_primer, amplicon, 'anti', \n",
    "                           pcr_predict_model,\n",
    "                           attributes=['align_score','mis_matches', 'three_prime_mm', 'three_prime_overhang'],\n",
    "                           ReturnPassProb=False)\n",
    "alt_p=PCRPredict(for_primer, rev_primer, amplicon, 'anti', \n",
    "                           alt_pcr_predict_model,\n",
    "                           attributes=['deltaTm', 'align_score','mis_matches', 'three_prime_mm', 'three_prime_overhang'],\n",
    "                           ReturnPassProb=False)\n",
    "\n",
    "\n",
    "\n",
    "print(p, alt_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bo_path=\"/tdata1/enterobase_20190205/BO_probedb.fa\"\n",
    "out_path = ud + 'CH_genome_map_align_model.csv' \n",
    "\n",
    "subj_name_Lst = [x[0] for x in list(subj_FDB.ListBlastDB())]\n",
    "\n",
    "pcr_predict_model=joblib.load('/home/ubuntu/git/Genotyper/src/Probe/PCRPredictModel.joblib')\n",
    "p_df, thermoLst_df=Run_ThermoPCRHit(faLst, subj_name_Lst, seqDict, bo_path, out_path, pcr_predict_model=pcr_predict_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aln_path=ud+'gis_cov2020align.aln'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON Schema Discovery for JSON Blast output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bo_json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-995ac9827b43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mJ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'root'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbo_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mud\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'schema.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bo_json' is not defined"
     ]
    }
   ],
   "source": [
    "#json_schema of BLAST output format: 15 (JSON combined)\n",
    "\n",
    "class jnode:\n",
    "    def __init__(self, key, obj, parent='', tab=''):\n",
    "        self.key=key\n",
    "        self.obj=obj\n",
    "        self.count=0\n",
    "        self.cardinality=0\n",
    "        self.type=str(type(obj))\n",
    "        self.leaf=False\n",
    "        if not(('dict' in self.type)or('list' in self.type)):\n",
    "            self.leaf=True\n",
    "        self.tab=tab\n",
    "        self.dict_children=[]\n",
    "        self.list_children=[]\n",
    "        self.compute_path(parent)\n",
    "        self.deep()\n",
    "    def compute_path(self, parent):\n",
    "        parent_path=''\n",
    "        if parent:\n",
    "            parent_path=parent.path\n",
    "            if 'list' in parent.type:\n",
    "                self.path=parent_path+\"[%s]\"%self.key\n",
    "            else:\n",
    "                self.path=parent_path+\"['%s']\"%self.key\n",
    "        else:\n",
    "            self.path=parent_path+\"['%s']\"%self.key\n",
    "    def deep(self):\n",
    "        #Fills out node representation\n",
    "        if 'dict' in self.type:\n",
    "            for key in self.obj.keys():\n",
    "                self.dict_children.append(jnode(key, self.obj[key], parent=self, tab=self.tab+'\\t'))\n",
    "        if 'list' in self.type:\n",
    "            for idx, obj in enumerate(self.obj):\n",
    "                self.list_children.append(jnode('%i'%idx, obj, parent=self, tab=self.tab+'['))\n",
    "        self.cardinality=len(self.dict_children)+len(self.list_children)\n",
    "    def print(self, string, fp=None):\n",
    "        if fp:\n",
    "            fp.write(\"%s\\t%s\\n\"%(self.path, string))\n",
    "        else:\n",
    "            print(string)\n",
    "    def display(self, fp=None):\n",
    "        if self.leaf:\n",
    "            self.print('%s%s (%s) Leaf:%s'%(self.tab, str(self.key), self.type, str(self.obj)), fp=fp)\n",
    "            return\n",
    "        self.print('%s%s (%s) [n=%i]'%(self.tab, self.key, self.type, self.cardinality), fp=fp)\n",
    "        for n in self.dict_children:\n",
    "            n.display(fp=fp)\n",
    "        for n in self.list_children:\n",
    "            n.display(fp=fp)\n",
    "    def compact(self):\n",
    "        pass\n",
    "    \n",
    "                                  \n",
    "\n",
    "J=jnode('root', bo_json)\n",
    "fp=open(ud+'schema.txt', 'w')\n",
    "J.display(fp=fp)\n",
    "fp.close()\n",
    "                                  \n",
    "#bo_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deprecation Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlastResult:\n",
    "    def __init__(self, hits, query_fa, subj_seq_dict):\n",
    "        self.query_fa=query_fa\n",
    "        self.query_label, self.query_seq=self.query_fa[:2]\n",
    "        self.hitLst=[]\n",
    "        self.subj_dict=subj_seq_dict\n",
    "        self.alignmentLst=[]\n",
    "        self.perfect_hits=0\n",
    "        self.parse_hits(hits)\n",
    "    def parse_hits(self, hits):\n",
    "        for hit in hits:\n",
    "            jHit=primer_hit(hit, self.query_fa)\n",
    "            jHit.set_subj_seq(self.subj_dict, seq_buffer=20)\n",
    "            self.hitLst.append(jHit)\n",
    "        self.count_perfect_hits()\n",
    "    def count_perfect_hits(self):\n",
    "        self.perfect_hits=0\n",
    "        for h in self.hitLst:\n",
    "            if (1.0-h.similarity_score)<0.01:\n",
    "                self.perfect_hits+=1\n",
    "    def display(self):\n",
    "        print(self.query_label, len(self.hitLst), self.perfect_hits)\n",
    "\n",
    "        \n",
    "            \n",
    "def ParseJSONBlastOutput(bo_path, primer_dict, subj_seq_dict):\n",
    "    bo_json=json.loads(open(bo_path).read())\n",
    "    blst=[]\n",
    "    for bb in bo_json[\"BlastOutput2\"]:\n",
    "        report=bb[\"report\"]\n",
    "        query_label=report['results'][\"search\"][\"query_title\"]\n",
    "        query_seq=primer_dict[query_label]\n",
    "        query_fa=[query_label, query_seq]\n",
    "        hits=report['results'][\"search\"][\"hits\"]\n",
    "        blst.append(BlastResult(hits, query_fa, subj_seq_dict))\n",
    "    return blst"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
